---
title             : "Peekbank Methods"
shorttitle        : "Peekbank"

author: 
  - name          : "First Author"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Ernst-August Doelle"
    affiliation   : "1,2"
    role:
      - "Writing - Review & Editing"
      - "Supervision"

affiliation:
  - id            : "1"
    institution   : "Wilhelm-Wundt-University"
  - id            : "2"
    institution   : "Konstanz Business School"

authornote: |
  Enter author note here.

abstract: |
  Lorem ipsum sit dolor hic sunt leones. 
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : "r-references.bib"

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction

[setup importance of word recognition/ LWL in particular - 1 or 2 paragraphs]

[define problem: how do we establish data analysis strategies that help us understand what we care about. Can we do this in a data-driven way]

goals:
- make data-driven recommendations based on Peekbank for data analysis strategies that maximize reliability
(- and validity? Would require incorporating some independent data/ trying to configure CDI pipeline)

We consider three commonly used dependent variables:
- accuracy (average accuracy within a fixed window)
- baseline-corrected accuracy (average accuracy subtracting an average baseline)
- reaction time (ms)

Core question is how to make decisions within the processing pipeline that maximize key measure characteristics for these commonly used dependent variables.
- exclusions
-- missing data on a trial level
-- missing data on a participant level
-- other exclusion criteria
- window size
- how to handle "sticky" trials/ zoners

Setup each recommendation:
- What window should you use?
- How to decide when to include trials and participants
- whether to do baseline corrections
- how to compute the most reliable reaction times
- how to get the most stable estimates of accuracy and reaction time for individuals


# Dataset and appraoch

Subset of peekbank that we are using

Descriptives on datasets/number of trials

Illustrate the ICC approach to reliability 

# Results

Recommendation 1: To maximize reliability, choose long time windows.

Recommendation 2: [recommendation about how to set missingness criteria & how to deal with zoners - probably err on the side of including more data?]
- how many trials?
- how much data per trial?
- zoning trials + zoning trials

Recommendation 3: RT guidance
- Reliability
- Windowing

Recommendation 4: Number of trials for stable individual kid measures and depending on research question- honing in on the individual differences question
- stable overall kid values
- within-participant designs/ detecting a condition difference
- item-level effects

# Discussion

- Validity questions - recommendations towards what we should do as a field to validate these measures


\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
